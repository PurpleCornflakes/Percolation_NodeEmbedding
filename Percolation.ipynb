{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Count $<i,j>$ pairs as inputs to learn Node Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "from random import choices\n",
    "import copy\n",
    "from scipy.sparse import issparse\n",
    "from statistics import mean,stdev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find percolation threshold. Avarage size of largest cluster $<s_{max}>$ v.s. $\\beta$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Transform edgelist to Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_matfile(file_, variable_name=\"network\", unDirected=True, unWeighted = True):\n",
    "    mat_variables = loadmat(file_)\n",
    "    mat_matrix = mat_variables[variable_name]\n",
    "    if issparse(mat_matrix):\n",
    "        if unDirected:\n",
    "            G = nx.Graph()\n",
    "        else:\n",
    "            G = nx.DiGraph()\n",
    "        '''\n",
    "        from_nodes: cx.row\n",
    "        to_nodes: cx.col\n",
    "        link weights: cx.data\n",
    "        '''\n",
    "        cx = mat_matrix.tocoo()\n",
    "        if unWeighted:\n",
    "            edge_list = np.array([cx.row, cx.col]).T\n",
    "            G.add_edges_from(edge_list)\n",
    "        else:\n",
    "            edge_list = np.array([cx.row, cx.col, cx.data]).T\n",
    "            G.add_weighted_edges_from(edge_list)\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we don't consider Directed/Weighted graph \n",
    "def percolate(G, beta, unWeighted = True):\n",
    "    edges_percolated = []\n",
    "    G_percolated = nx.Graph()\n",
    "    assert(G_percolated.number_of_nodes() == 0)\n",
    "    numPercolatedEdges = int(beta*G.number_of_edges())\n",
    "    G_percolated.add_nodes_from(list(G.nodes))\n",
    "    if unWeighted:\n",
    "        edges_percolated = choices(list(G.edges), k=numPercolatedEdges)\n",
    "        assert(len(edges_percolated) ==  numPercolatedEdges)\n",
    "        G_percolated.add_edges_from(edges_percolated)\n",
    "#     else:\n",
    "#         bond percolation probability depends on the edge's weight\n",
    "    return G_percolated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_average_Gc_sizes(G, betas, numIter, logging=False):\n",
    "    average_sizes_Gc = []\n",
    "    for beta in betas:\n",
    "        sizes_Gc = []\n",
    "        for i in range(numIter):\n",
    "            G_percolated = percolate(G, beta)\n",
    "            # graphs = list(nx.connected_component_subgraphs(G))\n",
    "            # largest percolated cluster\n",
    "            Gc = max(nx.connected_component_subgraphs(G_percolated), key=len)\n",
    "            sizes_Gc.append(Gc.number_of_nodes())\n",
    "        average_sizes_Gc.append([mean(sizes_Gc),stdev(sizes_Gc)])\n",
    "        if logging:\n",
    "            print(\"beta = {0:.4f} calculated\".format(beta))\n",
    "    return average_sizes_Gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # \"blogcatalog.mat\" is a undirected, unweighted graph\n",
    "    G_blogcatalog = load_matfile(file_ = \"blogcatalog.mat\")\n",
    "    assert(G_blogcatalog.number_of_nodes() == 10312)\n",
    "    assert(G_blogcatalog.number_of_edges() == 333983)\n",
    "    \n",
    "    # percolate\n",
    "    betas = np.linspace(0,0.5,50)\n",
    "    numIter = 2\n",
    "    aver_sizes_Gc = cal_average_Gc_sizes(G = G_blogcatalog, \n",
    "                                         betas = betas, \n",
    "                                         numIter = numIter,\n",
    "                                         logging = True)\n",
    "    \n",
    "    # plot \n",
    "    data = np.array(aver_sizes_Gc).T\n",
    "    means = data[0,:]\n",
    "    stdev = data[1,:]\n",
    "    plt.errorbar(betas, means, yerr=stdev, fmt='o')\n",
    "    plt.title('max(Gc_size)-beta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
